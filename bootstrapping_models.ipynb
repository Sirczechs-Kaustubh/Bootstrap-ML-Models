{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "hKukjYtm0U2F"
      },
      "outputs": [],
      "source": [
        "import scipy.io as sp\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def gcparser(mat):\n",
        "    \"\"\"\n",
        "    Extracts essential data from a Matlab formatted GCMS object loaded\n",
        "    by sio.loadmat and wrangles this into a pandas dataframe\n",
        "\n",
        "    Parameters:\n",
        "    mat (dict): Dictionary produced by loading a file using sio.loadmat\n",
        "\n",
        "    Return:\n",
        "    DataFrame: Total ion counts (TIC) arranged by samples (columns) and\n",
        "               retention time (rows), including y and label rows\n",
        "\n",
        "    \"\"\"\n",
        "    data = np.transpose(mat['XTIC'])\n",
        "    sample_names = np.hstack(np.hstack(mat['SAM'])).tolist()\n",
        "    RT = np.hstack(np.hstack(mat['RT'])).tolist()\n",
        "    y = np.hstack(mat['CLASS']).tolist()\n",
        "\n",
        "    # Create the dataframe for features\n",
        "    df_features = pd.DataFrame(data, columns=sample_names, index=RT)\n",
        "\n",
        "    # Create a separate series for labels\n",
        "    labels = pd.Series(y, index=sample_names, name='class')\n",
        "\n",
        "    return df_features, labels"
      ],
      "metadata": {
        "id": "Topkz0971LUS"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blood_features,blood_labels = gcparser(sp.loadmat(\"/content/drive/MyDrive/Namith/Blood_CDvCTRL.mat\"))"
      ],
      "metadata": {
        "id": "H5c6fadV1WXE"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "breath_features,breath_labels = gcparser(sp.loadmat(\"/content/drive/MyDrive/Namith/Breath_CDvCTRL.mat\"))\n",
        "faecal_features,faecal_labels = gcparser(sp.loadmat(\"/content/drive/MyDrive/Namith/Faecal_CDvCTRL.mat\"))\n",
        "urine_features,urine_labels = gcparser(sp.loadmat(\"/content/drive/MyDrive/Namith/Urine_CDvCTRL.mat\"))"
      ],
      "metadata": {
        "id": "o2TBdp-n3EGs"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.utils import resample"
      ],
      "metadata": {
        "id": "t0jeFScw3XbM"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "SMVSez78YlOV"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 1. Prepare the data\n",
        "X = blood_features.T  # Transpose to have samples as rows and features as columns\n",
        "y = blood_labels\n",
        "\n",
        "# 2. Define a function for bootstrap validation\n",
        "def bootstrap_validate(X, y, model, n_iterations=100):\n",
        "    n_samples = X.shape[0]\n",
        "    scores = {'accuracy': [], 'precision': [], 'recall': [], 'f1': []}\n",
        "\n",
        "    for _ in range(n_iterations):\n",
        "        # Bootstrap sampling\n",
        "        X_boot, y_boot = resample(X, y, n_samples=n_samples)\n",
        "\n",
        "        # Split the bootstrap sample\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X_boot, y_boot, test_size=0.3, random_state=42)\n",
        "\n",
        "        # Scale the features\n",
        "        scaler = StandardScaler()\n",
        "        X_train_scaled = scaler.fit_transform(X_train)\n",
        "        X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "        # Fit the model\n",
        "        model.fit(X_train_scaled, y_train)\n",
        "\n",
        "        # Predict\n",
        "        y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "        # Calculate metrics\n",
        "        scores['accuracy'].append(accuracy_score(y_test, y_pred))\n",
        "        scores['precision'].append(precision_score(y_test, y_pred, average='weighted'))\n",
        "        scores['recall'].append(recall_score(y_test, y_pred, average='weighted'))\n",
        "        scores['f1'].append(f1_score(y_test, y_pred, average='weighted'))\n",
        "\n",
        "    return {k: np.mean(v) for k, v in scores.items()}\n",
        "\n",
        "# 3. Create and evaluate SVM model\n",
        "svm_model = SVC(kernel='rbf', random_state=42)\n",
        "svm_scores = bootstrap_validate(X, y, svm_model)\n",
        "\n",
        "# 4. Create and evaluate Random Forest model\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_scores = bootstrap_validate(X, y, rf_model)\n",
        "\n",
        "# 5. Print results\n",
        "print(\"Results for Blood Sample\\n\\n\")\n",
        "print(\"SVM Results:\")\n",
        "for metric, score in svm_scores.items():\n",
        "    print(f\"{metric.capitalize()}: {score:.4f}\")\n",
        "\n",
        "print(\"\\nRandom Forest Results:\")\n",
        "for metric, score in rf_scores.items():\n",
        "    print(f\"{metric.capitalize()}: {score:.4f}\")\n",
        "\n",
        "# 6. Compare to random chance\n",
        "n_classes = len(np.unique(y))\n",
        "random_chance = 1 / n_classes\n",
        "\n",
        "print(f\"\\nRandom Chance Accuracy: {random_chance:.4f}\")\n",
        "\n",
        "# Determine best performing model\n",
        "best_model = \"SVM\" if svm_scores['accuracy'] > rf_scores['accuracy'] else \"Random Forest\"\n",
        "best_accuracy = max(svm_scores['accuracy'], rf_scores['accuracy'])\n",
        "\n",
        "print(f\"\\nBest performing model: {best_model}\")\n",
        "print(f\"Accuracy improvement over random chance: {best_accuracy - random_chance:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcXz1ZNBWQ87",
        "outputId": "5a628f27-c243-4af5-94ca-51242dbda3f8"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for Blood Sample\n",
            "\n",
            "\n",
            "SVM Results:\n",
            "Accuracy: 0.6360\n",
            "Precision: 0.6651\n",
            "Recall: 0.6360\n",
            "F1: 0.5928\n",
            "\n",
            "Random Forest Results:\n",
            "Accuracy: 0.7200\n",
            "Precision: 0.7765\n",
            "Recall: 0.7200\n",
            "F1: 0.7126\n",
            "\n",
            "Random Chance Accuracy: 0.5000\n",
            "\n",
            "Best performing model: Random Forest\n",
            "Accuracy improvement over random chance: 0.2200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 1. Prepare the data\n",
        "X = breath_features.T  # Transpose to have samples as rows and features as columns\n",
        "y = breath_labels\n",
        "\n",
        "# 2. Define a function for bootstrap validation\n",
        "def bootstrap_validate(X, y, model, n_iterations=100):\n",
        "    n_samples = X.shape[0]\n",
        "    scores = {'accuracy': [], 'precision': [], 'recall': [], 'f1': []}\n",
        "\n",
        "    for _ in range(n_iterations):\n",
        "        # Bootstrap sampling\n",
        "        X_boot, y_boot = resample(X, y, n_samples=n_samples)\n",
        "\n",
        "        # Split the bootstrap sample\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X_boot, y_boot, test_size=0.3, random_state=42)\n",
        "\n",
        "        # Scale the features\n",
        "        scaler = StandardScaler()\n",
        "        X_train_scaled = scaler.fit_transform(X_train)\n",
        "        X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "        # Fit the model\n",
        "        model.fit(X_train_scaled, y_train)\n",
        "\n",
        "        # Predict\n",
        "        y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "        # Calculate metrics\n",
        "        scores['accuracy'].append(accuracy_score(y_test, y_pred))\n",
        "        scores['precision'].append(precision_score(y_test, y_pred, average='weighted'))\n",
        "        scores['recall'].append(recall_score(y_test, y_pred, average='weighted'))\n",
        "        scores['f1'].append(f1_score(y_test, y_pred, average='weighted'))\n",
        "\n",
        "    return {k: np.mean(v) for k, v in scores.items()}\n",
        "\n",
        "# 3. Create and evaluate SVM model\n",
        "svm_model = SVC(kernel='rbf', random_state=42)\n",
        "svm_scores = bootstrap_validate(X, y, svm_model)\n",
        "\n",
        "# 4. Create and evaluate Random Forest model\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_scores = bootstrap_validate(X, y, rf_model)\n",
        "\n",
        "# 5. Print results\n",
        "print(\"Results for Breath Sample\\n\\n\")\n",
        "print(\"SVM Results:\")\n",
        "for metric, score in svm_scores.items():\n",
        "    print(f\"{metric.capitalize()}: {score:.4f}\")\n",
        "\n",
        "print(\"\\nRandom Forest Results:\")\n",
        "for metric, score in rf_scores.items():\n",
        "    print(f\"{metric.capitalize()}: {score:.4f}\")\n",
        "\n",
        "# 6. Compare to random chance\n",
        "n_classes = len(np.unique(y))\n",
        "random_chance = 1 / n_classes\n",
        "\n",
        "print(f\"\\nRandom Chance Accuracy: {random_chance:.4f}\")\n",
        "\n",
        "# Determine best performing model\n",
        "best_model = \"SVM\" if svm_scores['accuracy'] > rf_scores['accuracy'] else \"Random Forest\"\n",
        "best_accuracy = max(svm_scores['accuracy'], rf_scores['accuracy'])\n",
        "\n",
        "print(f\"\\nBest performing model: {best_model}\")\n",
        "print(f\"Accuracy improvement over random chance: {best_accuracy - random_chance:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJUUgjzAYnpu",
        "outputId": "021d8a3a-773b-496f-efa9-79150351b267"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for Breath Sample\n",
            "\n",
            "\n",
            "SVM Results:\n",
            "Accuracy: 0.5727\n",
            "Precision: 0.5260\n",
            "Recall: 0.5727\n",
            "F1: 0.4843\n",
            "\n",
            "Random Forest Results:\n",
            "Accuracy: 0.8055\n",
            "Precision: 0.8409\n",
            "Recall: 0.8055\n",
            "F1: 0.8005\n",
            "\n",
            "Random Chance Accuracy: 0.5000\n",
            "\n",
            "Best performing model: Random Forest\n",
            "Accuracy improvement over random chance: 0.3055\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 1. Prepare the data\n",
        "X = blood_features.T  # Transpose to have samples as rows and features as columns\n",
        "y = blood_labels\n",
        "\n",
        "# 2. Define a function for bootstrap validation\n",
        "def bootstrap_validate(X, y, model, n_iterations=100):\n",
        "    n_samples = X.shape[0]\n",
        "    scores = {'accuracy': [], 'precision': [], 'recall': [], 'f1': []}\n",
        "\n",
        "    for _ in range(n_iterations):\n",
        "        # Bootstrap sampling\n",
        "        X_boot, y_boot = resample(X, y, n_samples=n_samples)\n",
        "\n",
        "        # Split the bootstrap sample\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X_boot, y_boot, test_size=0.3, random_state=42)\n",
        "\n",
        "        # Scale the features\n",
        "        scaler = StandardScaler()\n",
        "        X_train_scaled = scaler.fit_transform(X_train)\n",
        "        X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "        # Fit the model\n",
        "        model.fit(X_train_scaled, y_train)\n",
        "\n",
        "        # Predict\n",
        "        y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "        # Calculate metrics\n",
        "        scores['accuracy'].append(accuracy_score(y_test, y_pred))\n",
        "        scores['precision'].append(precision_score(y_test, y_pred, average='weighted'))\n",
        "        scores['recall'].append(recall_score(y_test, y_pred, average='weighted'))\n",
        "        scores['f1'].append(f1_score(y_test, y_pred, average='weighted'))\n",
        "\n",
        "    return {k: np.mean(v) for k, v in scores.items()}\n",
        "\n",
        "# 3. Create and evaluate SVM model\n",
        "svm_model = SVC(kernel='rbf', random_state=42)\n",
        "svm_scores = bootstrap_validate(X, y, svm_model)\n",
        "\n",
        "# 4. Create and evaluate Random Forest model\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_scores = bootstrap_validate(X, y, rf_model)\n",
        "\n",
        "# 5. Print results\n",
        "print(\"Results for Faecal Sample\\n\\n\")\n",
        "print(\"SVM Results:\")\n",
        "for metric, score in svm_scores.items():\n",
        "    print(f\"{metric.capitalize()}: {score:.4f}\")\n",
        "\n",
        "print(\"\\nRandom Forest Results:\")\n",
        "for metric, score in rf_scores.items():\n",
        "    print(f\"{metric.capitalize()}: {score:.4f}\")\n",
        "\n",
        "# 6. Compare to random chance\n",
        "n_classes = len(np.unique(y))\n",
        "random_chance = 1 / n_classes\n",
        "\n",
        "print(f\"\\nRandom Chance Accuracy: {random_chance:.4f}\")\n",
        "\n",
        "# Determine best performing model\n",
        "best_model = \"SVM\" if svm_scores['accuracy'] > rf_scores['accuracy'] else \"Random Forest\"\n",
        "best_accuracy = max(svm_scores['accuracy'], rf_scores['accuracy'])\n",
        "\n",
        "print(f\"\\nBest performing model: {best_model}\")\n",
        "print(f\"Accuracy improvement over random chance: {best_accuracy - random_chance:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPJtwyjVYqIE",
        "outputId": "809b4f24-1e02-470a-f9b9-0e0e6f83983c"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for Faecal Sample\n",
            "\n",
            "\n",
            "SVM Results:\n",
            "Accuracy: 0.6310\n",
            "Precision: 0.6378\n",
            "Recall: 0.6310\n",
            "F1: 0.5861\n",
            "\n",
            "Random Forest Results:\n",
            "Accuracy: 0.7360\n",
            "Precision: 0.7825\n",
            "Recall: 0.7360\n",
            "F1: 0.7276\n",
            "\n",
            "Random Chance Accuracy: 0.5000\n",
            "\n",
            "Best performing model: Random Forest\n",
            "Accuracy improvement over random chance: 0.2360\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 1. Prepare the data\n",
        "X = blood_features.T  # Transpose to have samples as rows and features as columns\n",
        "y = blood_labels\n",
        "\n",
        "# 2. Define a function for bootstrap validation\n",
        "def bootstrap_validate(X, y, model, n_iterations=100):\n",
        "    n_samples = X.shape[0]\n",
        "    scores = {'accuracy': [], 'precision': [], 'recall': [], 'f1': []}\n",
        "\n",
        "    for _ in range(n_iterations):\n",
        "        # Bootstrap sampling\n",
        "        X_boot, y_boot = resample(X, y, n_samples=n_samples)\n",
        "\n",
        "        # Split the bootstrap sample\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X_boot, y_boot, test_size=0.3, random_state=42)\n",
        "\n",
        "        # Scale the features\n",
        "        scaler = StandardScaler()\n",
        "        X_train_scaled = scaler.fit_transform(X_train)\n",
        "        X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "        # Fit the model\n",
        "        model.fit(X_train_scaled, y_train)\n",
        "\n",
        "        # Predict\n",
        "        y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "        # Calculate metrics\n",
        "        scores['accuracy'].append(accuracy_score(y_test, y_pred))\n",
        "        scores['precision'].append(precision_score(y_test, y_pred, average='weighted'))\n",
        "        scores['recall'].append(recall_score(y_test, y_pred, average='weighted'))\n",
        "        scores['f1'].append(f1_score(y_test, y_pred, average='weighted'))\n",
        "\n",
        "    return {k: np.mean(v) for k, v in scores.items()}\n",
        "\n",
        "# 3. Create and evaluate SVM model\n",
        "svm_model = SVC(kernel='rbf', random_state=42)\n",
        "svm_scores = bootstrap_validate(X, y, svm_model)\n",
        "\n",
        "# 4. Create and evaluate Random Forest model\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_scores = bootstrap_validate(X, y, rf_model)\n",
        "\n",
        "# 5. Print results\n",
        "print(\"Results for Urine Sample\\n\\n\")\n",
        "print(\"SVM Results:\")\n",
        "for metric, score in svm_scores.items():\n",
        "    print(f\"{metric.capitalize()}: {score:.4f}\")\n",
        "\n",
        "print(\"\\nRandom Forest Results:\")\n",
        "for metric, score in rf_scores.items():\n",
        "    print(f\"{metric.capitalize()}: {score:.4f}\")\n",
        "\n",
        "# 6. Compare to random chance\n",
        "n_classes = len(np.unique(y))\n",
        "random_chance = 1 / n_classes\n",
        "\n",
        "print(f\"\\nRandom Chance Accuracy: {random_chance:.4f}\")\n",
        "\n",
        "# Determine best performing model\n",
        "best_model = \"SVM\" if svm_scores['accuracy'] > rf_scores['accuracy'] else \"Random Forest\"\n",
        "best_accuracy = max(svm_scores['accuracy'], rf_scores['accuracy'])\n",
        "\n",
        "print(f\"\\nBest performing model: {best_model}\")\n",
        "print(f\"Accuracy improvement over random chance: {best_accuracy - random_chance:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "en__9NPrYqn0",
        "outputId": "7b837eba-4bf5-4a28-f5a9-310495b4e147"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for Urine Sample\n",
            "\n",
            "\n",
            "SVM Results:\n",
            "Accuracy: 0.6430\n",
            "Precision: 0.6291\n",
            "Recall: 0.6430\n",
            "F1: 0.5909\n",
            "\n",
            "Random Forest Results:\n",
            "Accuracy: 0.7230\n",
            "Precision: 0.7812\n",
            "Recall: 0.7230\n",
            "F1: 0.7151\n",
            "\n",
            "Random Chance Accuracy: 0.5000\n",
            "\n",
            "Best performing model: Random Forest\n",
            "Accuracy improvement over random chance: 0.2230\n"
          ]
        }
      ]
    }
  ]
}